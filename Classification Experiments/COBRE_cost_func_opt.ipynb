{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af60c90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "from numpy.linalg import matrix_power as MP\n",
    "\n",
    "import scipy\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.io import savemat, loadmat\n",
    "from scipy.optimize import Bounds\n",
    "\n",
    "import networkx as nx\n",
    "import sys\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbba8920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF Version: 2.14.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"TF Version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9dbefa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 150 145\n"
     ]
    }
   ],
   "source": [
    "X_train_data = loadmat(\"./Dataset/COBRE_ROIdata_for_132_and_32_ROIs.mat\")['COBRE_ROIdata_32']\n",
    "\n",
    "N, T, num_samples = X_train_data.shape\n",
    "print(N, T, num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ede5a608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(np.array(X_train_data).flatten(), bins = 'auto')\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Histogram of generated data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4c988fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-1.  0.  0. ...  0.  0.  0.]\n",
      " [ 1. -1.  0. ...  0.  0.  0.]\n",
      " [ 0.  1. -1. ...  0.  0.  0.]\n",
      " ...\n",
      " [ 0.  0.  0. ...  1. -1.  0.]\n",
      " [ 0.  0.  0. ...  0.  1. -1.]\n",
      " [ 0.  0.  0. ...  0.  0.  1.]], shape=(150, 149), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "dt = np.zeros([T - 1, T])\n",
    "\n",
    "for i in range(T - 1):\n",
    "    dt[i, i] = -1\n",
    "    dt[i, i - 1] = 1\n",
    "\n",
    "d = dt.T\n",
    "d = np.concatenate((d, np.zeros([T, 1])), axis = 1) \n",
    "d[T - 1, T - 1] = -1\n",
    "d = d.T\n",
    "d[T - 1, T - 1] = 1 \n",
    "d[-1, -2] = 1\n",
    "d[0, -1] = 0\n",
    "d = d[:, :-1]\n",
    "d = tf.convert_to_tensor(d, dtype = \"float32\")\n",
    "\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3cda9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mul = np.eye(N) - np.ones([N, N])\n",
    "Mul = tf.convert_to_tensor(Mul, dtype = \"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88ee06ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_graph(X_training, N, top_values = 6):\n",
    "    distance_matrix = cdist(X_training, X_training, metric = 'euclidean')\n",
    "    \n",
    "    sorted_indices = distance_matrix.argsort(1)\n",
    "    TAdj = np.zeros([N, N])\n",
    "    \n",
    "    for i in range(N):\n",
    "        for j in range(1, top_values):\n",
    "            k = sorted_indices[i][j]\n",
    "            TAdj[i][k] = 1\n",
    "    \n",
    "    TAdj = (TAdj + TAdj.T) / 2\n",
    "    TAdj = np.where(TAdj > 0.1, 1, 0)\n",
    "    \n",
    "    Laplacian_init = np.diag(np.sum(TAdj, 1)) - TAdj\n",
    "    \n",
    "    return Laplacian_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c7d6e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "psi_cost = 0\n",
    "Laplacian = 0\n",
    "A_transform_cost = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cc374ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A - Predicted, B - Target matrix\n",
    "def costfunc(A, B):\n",
    "    global psi_cost\n",
    "    global Laplacian\n",
    "    global A_transform_cost\n",
    "\n",
    "    B_tmp = tf.squeeze(B)\n",
    "    data_fidelity = (tf.norm(tf.multiply(psi_cost, (A - B))) ** 2)\n",
    "    smoothness = tf.linalg.trace(tf.transpose(B_tmp) @ Laplacian @ B_tmp @ A_transform_cost)\n",
    "    L_cost = (tf.norm(Laplacian) ** 2)\n",
    "    Z_cost = (tf.norm(A_transform_cost) ** 2)\n",
    "    \n",
    "    return (smoothness) + (data_fidelity) + (L_cost) + (Z_cost)\n",
    "    \n",
    "def costfunc1(A, B):\n",
    "    global psi_cost\n",
    "    \n",
    "    data_fidelity = (tf.norm(tf.multiply(psi_cost, (A - B))) ** 2)\n",
    "    return (data_fidelity)\n",
    "\n",
    "def costfunc2(A, B):\n",
    "    global Laplacian\n",
    "    global A_transform_cost\n",
    "    \n",
    "    B_tmp = tf.squeeze(B)\n",
    "    smoothness = tf.linalg.trace(tf.transpose(B_tmp) @ Laplacian @ B_tmp @ A_transform_cost)\n",
    "    \n",
    "    return (smoothness)\n",
    "\n",
    "def costfunc3(A, B):\n",
    "    global Laplacian\n",
    "    \n",
    "    L_cost = (tf.norm(Laplacian) ** 2)\n",
    "    \n",
    "    return (L_cost)\n",
    "\n",
    "def costfunc4(A, B):\n",
    "    global A_transform_cost\n",
    "    \n",
    "    Z_cost = (tf.norm(A_transform_cost) ** 2)\n",
    "    \n",
    "    return (Z_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2cd973ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(X_train_concatenated, X_train, params, p1, p2, d):\n",
    "    \n",
    "    def data_inpainting(loop_b, reg, psi, Y, Lk, AAT):\n",
    "\n",
    "        Xk = tf.zeros_like(Y)\n",
    "        Zk = -(tf.multiply(psi, Xk) - Y + (2 * reg * (Lk @ Xk @ AAT)))\n",
    "\n",
    "        for i in range(loop_b):\n",
    "            fdx_xk = tf.multiply(psi, Xk) - Y + (2 * reg * (Lk @ Xk @ AAT))\n",
    "            fdx_zk = tf.multiply(psi, Zk) - Y + (2 * reg * (Lk @ Zk @ AAT))\n",
    "\n",
    "            tau = tf.linalg.trace(tf.transpose(fdx_xk) @ Zk) / tf.linalg.trace(tf.transpose((Y + fdx_zk)) @ Zk)\n",
    "            \n",
    "            Xk_1 = Xk - (tau * Zk)\n",
    "\n",
    "            fdx_xk_1 = tf.multiply(psi, Xk_1) - Y + (2 * reg * (Lk @ Xk_1 @ AAT))\n",
    "            gamma = (tf.norm(fdx_xk_1) ** 2) / (tf.norm(fdx_xk) ** 2)\n",
    "\n",
    "            Zk_1 = (gamma * Zk) - fdx_xk_1\n",
    "\n",
    "            Xk = Xk_1\n",
    "            Zk = Zk_1\n",
    "        \n",
    "        return Xk_1\n",
    "    \n",
    "    def graph_learning(loop_c, alpha, beta, X, Lk, AAT):\n",
    "        \n",
    "        # Computing the smoothness term\n",
    "        X_AAT_XT = tf.matmul(X, tf.matmul(AAT, tf.transpose(X)))\n",
    "        \n",
    "        for i in range(loop_c):\n",
    "\n",
    "            # Extracting the adjacency matrix from the Laplacian\n",
    "            adj_i = tf.multiply(Mul, Lk)\n",
    "\n",
    "            # Computing the gradient with respect to laplacian\n",
    "            fdL_Lk = X_AAT_XT + (beta * Lk)\n",
    "            \n",
    "            # Extracting the adjacency matrix from the gradient\n",
    "            adj_grad = tf.multiply(Mul, fdL_Lk)\n",
    "            \n",
    "            # Computing the new adjacency\n",
    "            adj_i1 = adj_i - (alpha * adj_grad)\n",
    "            \n",
    "            # Avoiding any negative values\n",
    "            adj_i1 = tf.nn.relu(adj_i1)\n",
    "\n",
    "            # Computing the new laplacian\n",
    "            Lk_1 = tf.linalg.diag(tf.math.reduce_sum(adj_i1, 1)) - adj_i1\n",
    "            \n",
    "            # Updating the laplacian\n",
    "            Lk = Lk_1\n",
    "        \n",
    "        # print(adj_i[0, :], alpha * adj_grad[0, :])\n",
    "        return Lk\n",
    "    \n",
    "    y = X_train_concatenated\n",
    "    \n",
    "    psi = y[0,:,T:]\n",
    "    global psi_cost\n",
    "    psi_cost = psi\n",
    "\n",
    "    psi = tf.convert_to_tensor(psi, dtype = \"float32\")\n",
    "\n",
    "    X_in = y[0,:,:T]\n",
    "    X_in = psi * tf.convert_to_tensor(X_in, dtype = \"float32\")\n",
    "    Y = X_in\n",
    "    \n",
    "    loop_a, loop_b, loop_c, reg, alpha, beta, threshold, Lk = params\n",
    "    \n",
    "    LT = tf.matmul(d, tf.transpose(d))\n",
    "    LT = tf.convert_to_tensor(LT, dtype = \"float32\")\n",
    "    \n",
    "    A_transform = tf.eye(T) + (p1 * MP(LT, 1)) + (p2 * MP(LT, 2))\n",
    "    AAT = A_transform\n",
    "    \n",
    "    global A_transform_cost\n",
    "    A_transform_cost = AAT\n",
    "    \n",
    "    for i in range(loop_a):\n",
    "            \n",
    "        Xk_1 = data_inpainting(loop_b, reg, psi, Y, Lk, AAT)\n",
    "\n",
    "        Xk_1_gt = X_in + tf.multiply((tf.ones(psi.shape) - psi), Xk_1)\n",
    "\n",
    "        Lk_1 = graph_learning(loop_c, alpha, beta, Xk_1_gt, Lk, AAT)\n",
    "\n",
    "        Adj = tf.linalg.diag(tf.linalg.diag_part(Lk_1)) - Lk_1\n",
    "\n",
    "        n = tf.math.count_nonzero(Adj, dtype=\"float32\")\n",
    "        mean = tf.math.reduce_sum(Adj) / n\n",
    "        Adj = tf.math.subtract(Adj, (threshold * mean))\n",
    "\n",
    "        Adj = tf.nn.relu(Adj)\n",
    "        # Adj = tf.math.sign(Adj)\n",
    "\n",
    "        Lk_1 = tf.linalg.diag(tf.math.reduce_sum(Adj, 1)) - Adj\n",
    "\n",
    "        Lk = Lk_1\n",
    "        \n",
    "        global Laplacian\n",
    "        Laplacian = Lk\n",
    "    \n",
    "    Xk = data_inpainting(loop_b, reg, psi, Y, Lk, AAT)\n",
    "    tmp = np.array([costfunc1(X_train, Xk), costfunc2(X_train, Xk), \n",
    "                    costfunc3(X_train, Xk), costfunc4(X_train, Xk)])\n",
    "\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "975a74c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_psi = 1\n",
    "# sensing_ratio = [0.01, 0.05, 0.10, 0.15, 0.20, 0.25, 0.30, 0.35, 0.4, 0.45, 0.5]\n",
    "# sensing_ratio = (1 + np.arange(50)) / 100\n",
    "# sensing_ratio = np.arange(1.0, 51.0, 1.0) / 100\n",
    "sensing_ratio = 0.1\n",
    "\n",
    "p1, p2 = 8.0, 10.0\n",
    "\n",
    "loop_a = 5\n",
    "loop_b = 10\n",
    "loop_c = 10 \n",
    "reg_init = 1.0e-2\n",
    "alpha_init = 1.0e-4\n",
    "beta_init = 1.0e-2\n",
    "threshold_init = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d218c6cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensing Ratio: 10%\n",
      "[1.e-02 1.e-04 1.e-04 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.0001, 0.0001, 1e-06] \n",
      "\n",
      "[1.e-03 1.e-04 1.e-05 1.e-06]\n",
      "The optimal coefficients are: [0.001, 0.0001, 1e-05, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-04 1.e-05 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.0001, 1e-05, 1e-06] \n",
      "\n",
      "[1.e-03 1.e-04 1.e-05 1.e-06]\n",
      "The optimal coefficients are: [0.001, 0.0001, 1e-05, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-04 1.e-04 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.0001, 0.0001, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-03 1.e-03 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.001, 0.001, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-04 1.e-04 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.0001, 0.0001, 1e-06] \n",
      "\n",
      "[1.e-03 1.e-04 1.e-05 1.e-06]\n",
      "The optimal coefficients are: [0.001, 0.0001, 1e-05, 1e-06] \n",
      "\n",
      "[1.e-03 1.e-04 1.e-05 1.e-06]\n",
      "The optimal coefficients are: [0.001, 0.0001, 1e-05, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-03 1.e-03 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.001, 0.001, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-04 1.e-05 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.0001, 1e-05, 1e-06] \n",
      "\n",
      "[1.e-03 1.e-04 1.e-05 1.e-06]\n",
      "The optimal coefficients are: [0.001, 0.0001, 1e-05, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-04 1.e-04 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.0001, 0.0001, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-04 1.e-04 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.0001, 0.0001, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-03 1.e-03 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.001, 0.001, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-04 1.e-04 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.0001, 0.0001, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-03 1.e-03 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.001, 0.001, 1e-06] \n",
      "\n",
      "[1.e-03 1.e-04 1.e-04 1.e-06]\n",
      "The optimal coefficients are: [0.001, 0.0001, 0.0001, 1e-06] \n",
      "\n",
      "[1.e-03 1.e-04 1.e-05 1.e-06]\n",
      "The optimal coefficients are: [0.001, 0.0001, 1e-05, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-03 1.e-03 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.001, 0.001, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-03 1.e-03 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.001, 0.001, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-04 1.e-04 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.0001, 0.0001, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-03 1.e-04 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.001, 0.0001, 1e-06] \n",
      "\n",
      "[1.e-03 1.e-04 1.e-05 1.e-06]\n",
      "The optimal coefficients are: [0.001, 0.0001, 1e-05, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-04 1.e-04 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.0001, 0.0001, 1e-06] \n",
      "\n",
      "[1.e-03 1.e-04 1.e-06 1.e-06]\n",
      "The optimal coefficients are: [0.001, 0.0001, 1e-06, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-04 1.e-05 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.0001, 1e-05, 1e-06] \n",
      "\n",
      "[1.e-03 1.e-04 1.e-04 1.e-06]\n",
      "The optimal coefficients are: [0.001, 0.0001, 0.0001, 1e-06] \n",
      "\n",
      "[1.e-03 1.e-04 1.e-04 1.e-06]\n",
      "The optimal coefficients are: [0.001, 0.0001, 0.0001, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-03 1.e-03 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.001, 0.001, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-03 1.e-03 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.001, 0.001, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-04 1.e-04 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.0001, 0.0001, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-04 1.e-04 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.0001, 0.0001, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-04 1.e-04 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.0001, 0.0001, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-04 1.e-04 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.0001, 0.0001, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-04 1.e-04 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.0001, 0.0001, 1e-06] \n",
      "\n",
      "[1.e-03 1.e-04 1.e-05 1.e-06]\n",
      "The optimal coefficients are: [0.001, 0.0001, 1e-05, 1e-06] \n",
      "\n",
      "[1.e-03 1.e-04 1.e-05 1.e-06]\n",
      "The optimal coefficients are: [0.001, 0.0001, 1e-05, 1e-06] \n",
      "\n",
      "[1.e-03 1.e-04 1.e-05 1.e-06]\n",
      "The optimal coefficients are: [0.001, 0.0001, 1e-05, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-03 1.e-03 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.001, 0.001, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-04 1.e-04 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.0001, 0.0001, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-04 1.e-04 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.0001, 0.0001, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-03 1.e-03 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.001, 0.001, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-04 1.e-05 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.0001, 1e-05, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-03 1.e-03 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.001, 0.001, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-04 1.e-04 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.0001, 0.0001, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-04 1.e-04 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.0001, 0.0001, 1e-06] \n",
      "\n",
      "[1.e-03 1.e-04 1.e-05 1.e-06]\n",
      "The optimal coefficients are: [0.001, 0.0001, 1e-05, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-04 1.e-05 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.0001, 1e-05, 1e-06] \n",
      "\n",
      "[1.e-03 1.e-04 1.e-05 1.e-06]\n",
      "The optimal coefficients are: [0.001, 0.0001, 1e-05, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-03 1.e-04 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.001, 0.0001, 1e-06] \n",
      "\n",
      "[1.e-03 1.e-04 1.e-05 1.e-06]\n",
      "The optimal coefficients are: [0.001, 0.0001, 1e-05, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-04 1.e-04 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.0001, 0.0001, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-04 1.e-04 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.0001, 0.0001, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-04 1.e-04 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.0001, 0.0001, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-04 1.e-05 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.0001, 1e-05, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-04 1.e-04 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.0001, 0.0001, 1e-06] \n",
      "\n",
      "[1.e-03 1.e-04 1.e-05 1.e-06]\n",
      "The optimal coefficients are: [0.001, 0.0001, 1e-05, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-04 1.e-04 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.0001, 0.0001, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-04 1.e-04 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.0001, 0.0001, 1e-06] \n",
      "\n",
      "[1.e-03 1.e-04 1.e-05 1.e-06]\n",
      "The optimal coefficients are: [0.001, 0.0001, 1e-05, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-04 1.e-04 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.0001, 0.0001, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-03 1.e-04 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.001, 0.0001, 1e-06] \n",
      "\n",
      "[1.e-03 1.e-04 1.e-05 1.e-06]\n",
      "The optimal coefficients are: [0.001, 0.0001, 1e-05, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-04 1.e-04 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.0001, 0.0001, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-03 1.e-03 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.001, 0.001, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-04 1.e-04 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.0001, 0.0001, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-04 1.e-04 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.0001, 0.0001, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-04 1.e-04 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.0001, 0.0001, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-04 1.e-05 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.0001, 1e-05, 1e-06] \n",
      "\n",
      "[1.e-03 1.e-04 1.e-05 1.e-06]\n",
      "The optimal coefficients are: [0.001, 0.0001, 1e-05, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-04 1.e-05 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.0001, 1e-05, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-03 1.e-03 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.001, 0.001, 1e-06] \n",
      "\n",
      "[1.e-03 1.e-04 1.e-05 1.e-06]\n",
      "The optimal coefficients are: [0.001, 0.0001, 1e-05, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-03 1.e-03 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.001, 0.001, 1e-06] \n",
      "\n",
      "[1.e-04 1.e-04 1.e-07 1.e-06]\n",
      "The optimal coefficients are: [0.0001, 0.0001, 1e-07, 1e-06] \n",
      "\n",
      "[1.e-03 1.e-04 1.e-05 1.e-06]\n",
      "The optimal coefficients are: [0.001, 0.0001, 1e-05, 1e-06] \n",
      "\n",
      "[1.e-03 1.e-04 1.e-05 1.e-06]\n",
      "The optimal coefficients are: [0.001, 0.0001, 1e-05, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-04 1.e-05 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.0001, 1e-05, 1e-06] \n",
      "\n",
      "[1.e-04 1.e-04 1.e-07 1.e-06]\n",
      "The optimal coefficients are: [0.0001, 0.0001, 1e-07, 1e-06] \n",
      "\n",
      "[1.e-03 1.e-04 1.e-05 1.e-06]\n",
      "The optimal coefficients are: [0.001, 0.0001, 1e-05, 1e-06] \n",
      "\n",
      "[1.e-03 1.e-04 1.e-06 1.e-06]\n",
      "The optimal coefficients are: [0.001, 0.0001, 1e-06, 1e-06] \n",
      "\n",
      "[1.e-03 1.e-04 1.e-06 1.e-06]\n",
      "The optimal coefficients are: [0.001, 0.0001, 1e-06, 1e-06] \n",
      "\n",
      "[1.e-03 1.e-04 1.e-06 1.e-06]\n",
      "The optimal coefficients are: [0.001, 0.0001, 1e-06, 1e-06] \n",
      "\n",
      "[1.e-03 1.e-04 1.e-06 1.e-06]\n",
      "The optimal coefficients are: [0.001, 0.0001, 1e-06, 1e-06] \n",
      "\n",
      "[1.e-03 1.e-04 1.e-06 1.e-06]\n",
      "The optimal coefficients are: [0.001, 0.0001, 1e-06, 1e-06] \n",
      "\n",
      "[1.e-03 1.e-04 1.e-05 1.e-06]\n",
      "The optimal coefficients are: [0.001, 0.0001, 1e-05, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-03 1.e-04 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.001, 0.0001, 1e-06] \n",
      "\n",
      "[1.e-04 1.e-04 1.e-07 1.e-06]\n",
      "The optimal coefficients are: [0.0001, 0.0001, 1e-07, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-04 1.e-04 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.0001, 0.0001, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-04 1.e-04 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.0001, 0.0001, 1e-06] \n",
      "\n",
      "[1.e-03 1.e-04 1.e-05 1.e-06]\n",
      "The optimal coefficients are: [0.001, 0.0001, 1e-05, 1e-06] \n",
      "\n",
      "[1.e-03 1.e-04 1.e-05 1.e-06]\n",
      "The optimal coefficients are: [0.001, 0.0001, 1e-05, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-03 1.e-03 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.001, 0.001, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-03 1.e-03 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.001, 0.001, 1e-06] \n",
      "\n",
      "[1.e-03 1.e-04 1.e-05 1.e-06]\n",
      "The optimal coefficients are: [0.001, 0.0001, 1e-05, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-04 1.e-04 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.0001, 0.0001, 1e-06] \n",
      "\n",
      "[1.e-03 1.e-04 1.e-05 1.e-06]\n",
      "The optimal coefficients are: [0.001, 0.0001, 1e-05, 1e-06] \n",
      "\n",
      "[1.e-03 1.e-04 1.e-06 1.e-06]\n",
      "The optimal coefficients are: [0.001, 0.0001, 1e-06, 1e-06] \n",
      "\n",
      "[1.e-03 1.e-04 1.e-05 1.e-06]\n",
      "The optimal coefficients are: [0.001, 0.0001, 1e-05, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-04 1.e-04 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.0001, 0.0001, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-04 1.e-05 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.0001, 1e-05, 1e-06] \n",
      "\n",
      "[1.e-03 1.e-04 1.e-05 1.e-06]\n",
      "The optimal coefficients are: [0.001, 0.0001, 1e-05, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-04 1.e-04 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.0001, 0.0001, 1e-06] \n",
      "\n",
      "[1.e-03 1.e-04 1.e-06 1.e-06]\n",
      "The optimal coefficients are: [0.001, 0.0001, 1e-06, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-03 1.e-03 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.001, 0.001, 1e-06] \n",
      "\n",
      "[1.e-04 1.e-04 1.e-07 1.e-06]\n",
      "The optimal coefficients are: [0.0001, 0.0001, 1e-07, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-04 1.e-04 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.0001, 0.0001, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-04 1.e-04 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.0001, 0.0001, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-04 1.e-04 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.0001, 0.0001, 1e-06] \n",
      "\n",
      "[1.e-03 1.e-04 1.e-05 1.e-06]\n",
      "The optimal coefficients are: [0.001, 0.0001, 1e-05, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-03 1.e-03 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.001, 0.001, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-04 1.e-03 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.0001, 0.001, 1e-06] \n",
      "\n",
      "[1.e-03 1.e-04 1.e-06 1.e-06]\n",
      "The optimal coefficients are: [0.001, 0.0001, 1e-06, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-04 1.e-04 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.0001, 0.0001, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-04 1.e-04 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.0001, 0.0001, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-04 1.e-04 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.0001, 0.0001, 1e-06] \n",
      "\n",
      "[1.e-03 1.e-04 1.e-06 1.e-06]\n",
      "The optimal coefficients are: [0.001, 0.0001, 1e-06, 1e-06] \n",
      "\n",
      "[1.e-03 1.e-04 1.e-05 1.e-06]\n",
      "The optimal coefficients are: [0.001, 0.0001, 1e-05, 1e-06] \n",
      "\n",
      "[1.e-04 1.e-04 1.e-07 1.e-06]\n",
      "The optimal coefficients are: [0.0001, 0.0001, 1e-07, 1e-06] \n",
      "\n",
      "[1.e-03 1.e-04 1.e-06 1.e-06]\n",
      "The optimal coefficients are: [0.001, 0.0001, 1e-06, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-04 1.e-04 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.0001, 0.0001, 1e-06] \n",
      "\n",
      "[1.e-03 1.e-04 1.e-04 1.e-06]\n",
      "The optimal coefficients are: [0.001, 0.0001, 0.0001, 1e-06] \n",
      "\n",
      "[1.e-03 1.e-04 1.e-06 1.e-06]\n",
      "The optimal coefficients are: [0.001, 0.0001, 1e-06, 1e-06] \n",
      "\n",
      "[1.e-03 1.e-04 1.e-05 1.e-06]\n",
      "The optimal coefficients are: [0.001, 0.0001, 1e-05, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-04 1.e-04 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.0001, 0.0001, 1e-06] \n",
      "\n",
      "[1.e-03 1.e-04 1.e-06 1.e-06]\n",
      "The optimal coefficients are: [0.001, 0.0001, 1e-06, 1e-06] \n",
      "\n",
      "[1.e-03 1.e-04 1.e-06 1.e-06]\n",
      "The optimal coefficients are: [0.001, 0.0001, 1e-06, 1e-06] \n",
      "\n",
      "[1.e-03 1.e-04 1.e-05 1.e-06]\n",
      "The optimal coefficients are: [0.001, 0.0001, 1e-05, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-03 1.e-03 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.001, 0.001, 1e-06] \n",
      "\n",
      "[1.e-03 1.e-04 1.e-06 1.e-06]\n",
      "The optimal coefficients are: [0.001, 0.0001, 1e-06, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-04 1.e-04 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.0001, 0.0001, 1e-06] \n",
      "\n",
      "[1.e-03 1.e-04 1.e-05 1.e-06]\n",
      "The optimal coefficients are: [0.001, 0.0001, 1e-05, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-03 1.e-04 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.001, 0.0001, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-04 1.e-04 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.0001, 0.0001, 1e-06] \n",
      "\n",
      "[1.e-03 1.e-04 1.e-06 1.e-06]\n",
      "The optimal coefficients are: [0.001, 0.0001, 1e-06, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-04 1.e-04 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.0001, 0.0001, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-04 1.e-04 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.0001, 0.0001, 1e-06] \n",
      "\n",
      "[1.e-03 1.e-04 1.e-05 1.e-06]\n",
      "The optimal coefficients are: [0.001, 0.0001, 1e-05, 1e-06] \n",
      "\n",
      "[1.e-03 1.e-04 1.e-05 1.e-06]\n",
      "The optimal coefficients are: [0.001, 0.0001, 1e-05, 1e-06] \n",
      "\n",
      "[1.e-03 1.e-04 1.e-06 1.e-06]\n",
      "The optimal coefficients are: [0.001, 0.0001, 1e-06, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-04 1.e-04 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.0001, 0.0001, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-04 1.e-04 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.0001, 0.0001, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-04 1.e-05 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.0001, 1e-05, 1e-06] \n",
      "\n",
      "[1.e-02 1.e-04 1.e-04 1.e-06]\n",
      "The optimal coefficients are: [0.01, 0.0001, 0.0001, 1e-06] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_psi = []\n",
    "opt_coeffs = []\n",
    "\n",
    "print(f\"Sensing Ratio: {int(100 * sensing_ratio)}%\")\n",
    "\n",
    "for i in range(num_samples):\n",
    "    X_train = X_train_data[:, :, i]\n",
    "    Lap_init = initial_graph(X_train, N)\n",
    "\n",
    "    params = [loop_a, loop_b, loop_c, reg_init, alpha_init, beta_init, threshold_init, Lap_init]\n",
    "        \n",
    "    M = int(sensing_ratio * T)\n",
    "    X_train_missing = np.zeros([no_of_psi, N, T])\n",
    "    X_train_concatenated = np.zeros([no_of_psi, N, 2 * T])\n",
    "\n",
    "    for i in range(no_of_psi):\n",
    "        psi_k = np.array([0] * (N * M) + [1] * (N * (T - M)))\n",
    "        np.random.shuffle(psi_k)\n",
    "        psi_k = psi_k.reshape([N, T])\n",
    "        all_psi.append(psi_k)\n",
    "        X_train_missing[i, : , : ] = X_train * psi_k\n",
    "        X_train_concatenated[i, :, :] = np.concatenate((X_train_missing[i], psi_k), axis = 1)\n",
    "\n",
    "    Laplacian = 0\n",
    "\n",
    "    c1_test = forward_pass(X_train_concatenated, X_train, params, p1, p2, d)\n",
    "\n",
    "    mul = 10 ** (-np.floor(np.log10(c1_test), dtype = \"float\"))\n",
    "    print(mul)\n",
    "\n",
    "    opt_coeffs.append(np.array(mul))\n",
    "    print(f\"The optimal coefficients are:\", list(opt_coeffs[-1]), f\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "726e8466",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(opt_coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adae8de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"./Outputs/COBRE_cost_func_coeffs.npy\", opt_coeffs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
